package docs

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"text/template"

	"github.com/ziadkadry99/auto-doc/internal/diagrams"
	"github.com/ziadkadry99/auto-doc/internal/indexer"
	"github.com/ziadkadry99/auto-doc/internal/llm"
)

// Feature represents a logical grouping of related files in the project.
type Feature struct {
	Name                string
	Slug                string
	Description         string
	DetailedDescription string // Multi-paragraph deep description generated by a follow-up LLM call.
	Files               []string
}

// EntryPoint represents a way users or systems interact with the project.
type EntryPoint struct {
	Name, Type, Description string
}

// ExitPoint represents an output or side effect produced by the project.
type ExitPoint struct {
	Name, Type, Description string
}

// UsageExample represents a concrete usage example with a command and description.
type UsageExample struct {
	Title, Command, Description string
}

// EnhancedIndex holds data for the enhanced home page generation.
type EnhancedIndex struct {
	ProjectName     string
	ProjectOverview string
	Features        []Feature
	EntryPoints     []EntryPoint
	ExitPoints      []ExitPoint
	Usages          []UsageExample
	ArchDiagram     string
	DepDiagram      string
	Analyses        []indexer.FileAnalysis
}

// GenerateEnhancedIndex creates an enhanced index.md with project overview,
// feature-based TOC, and Mermaid diagrams. It also writes per-feature pages
// under features/{slug}.md.
func (g *DocGenerator) GenerateEnhancedIndex(ctx context.Context, analyses []indexer.FileAnalysis, provider llm.Provider, model string) error {
	// Build compact file summary for the LLM (truncate long summaries).
	var summary strings.Builder
	for _, a := range analyses {
		deps := ""
		if len(a.Dependencies) > 0 {
			var depNames []string
			for _, d := range a.Dependencies {
				depNames = append(depNames, d.Name)
			}
			deps = " [deps: " + strings.Join(depNames, ", ") + "]"
		}
		// Use a short version of the summary to keep the prompt compact.
		shortSummary := a.Summary
		if len(shortSummary) > 200 {
			shortSummary = shortSummary[:200] + "..."
		}
		fmt.Fprintf(&summary, "- %s: %s%s\n", a.FilePath, shortSummary, deps)
	}

	// If business context was provided, prepend it to the prompt.
	var contextSection string
	if g.BusinessContext != nil && !g.BusinessContext.IsEmpty() {
		contextSection = fmt.Sprintf("Business context provided by the project maintainer:\n%s\n", g.BusinessContext.ToPromptSection())
	}

	prompt := fmt.Sprintf(`%sGiven the following source files and their summaries, analyze this codebase.

Files:
%s

Respond with sections:

===PROJECT_OVERVIEW===
3-5 paragraph overview of what this project does, who it's for, main capabilities, technical approach.

===FEATURES===
Each feature as:
FEATURE: Name
DESCRIPTION: 2-4 sentences describing this feature.
FILES: comma-separated file paths

Every file must belong to exactly one feature. Aim for 4-12 features.

===ENTRY_POINTS===
List every way a user or external system can interact with this project (CLI commands, API endpoints, MCP tools, event handlers, etc.).
Each entry as:
ENTRY: Name of the entry point
TYPE: Category (e.g. CLI Command, API Endpoint, MCP Tool, Event Handler)
DESCRIPTION: What it does

===EXIT_POINTS===
List every output or side effect this project produces (files written, API calls made, databases updated, messages sent, etc.).
Each entry as:
EXIT: Name of the exit point
TYPE: Category (e.g. File Output, API Call, Database Write, Network Request)
DESCRIPTION: What it produces

===USAGES===
Provide concrete usage examples showing every major way to use this tool.
Each example as:
EXAMPLE: Short title
COMMAND: The exact command or code to run
DESCRIPTION: What happens when you run this and what to expect

===ARCHITECTURE_DIAGRAM===
A Mermaid "graph TD" diagram showing the high-level architecture.
Show layers (e.g. API, Core, Storage, Tools) and key components within each.
Use subgraph blocks for layers. Show real data-flow arrows between components.
Only output the Mermaid code, no fences.`, contextSection, summary.String())

	resp, err := provider.Complete(ctx, llm.CompletionRequest{
		Model: model,
		Messages: []llm.Message{
			{Role: llm.RoleSystem, Content: "You are a software architect analyzing a codebase. Be concise and factual. Group files by logical feature areas."},
			{Role: llm.RoleUser, Content: prompt},
		},
		MaxTokens:   12288,
		Temperature: 0.3,
	})
	if err != nil {
		return fmt.Errorf("enhanced index LLM call failed: %w", err)
	}

	data := parseEnhancedIndexResponse(resp.Content)
	data.ProjectName = filepath.Base(g.OutputDir)
	data.Analyses = analyses

	// Build dependency diagram from file analyses.
	depMap := make(map[string][]string)
	for _, a := range analyses {
		if len(a.Dependencies) > 0 {
			var deps []string
			for _, d := range a.Dependencies {
				deps = append(deps, d.Name)
			}
			depMap[a.FilePath] = deps
		}
	}
	if len(depMap) > 0 {
		data.DepDiagram = diagrams.DependencyDiagram(depMap)
	}

	// Generate detailed descriptions for each feature via concurrent LLM calls.
	g.generateFeatureDetails(ctx, &data, analyses, provider, model)

	// Generate interactive component map.
	if err := g.GenerateInteractiveMap(analyses, data.Features); err != nil {
		fmt.Fprintf(os.Stderr, "Warning: interactive map generation failed: %v\n", err)
	}

	// Write enhanced index.md.
	docsDir := filepath.Join(g.OutputDir, "docs")
	if err := os.MkdirAll(docsDir, 0o755); err != nil {
		return err
	}

	tmpl, err := template.New("enhancedIndex").Funcs(templateFuncs).Parse(enhancedIndexTemplate)
	if err != nil {
		return fmt.Errorf("parsing enhanced index template: %w", err)
	}

	indexPath := filepath.Join(docsDir, "index.md")
	f, err := os.Create(indexPath)
	if err != nil {
		return err
	}
	defer f.Close()

	if err := tmpl.Execute(f, data); err != nil {
		return fmt.Errorf("executing enhanced index template: %w", err)
	}

	// Write per-feature pages.
	featuresDir := filepath.Join(docsDir, "features")
	if err := os.MkdirAll(featuresDir, 0o755); err != nil {
		return err
	}

	featureTmpl, err := template.New("feature").Funcs(templateFuncs).Parse(featureTemplate)
	if err != nil {
		return fmt.Errorf("parsing feature template: %w", err)
	}

	// Build a lookup from file path to analysis for the feature pages.
	analysisMap := make(map[string]indexer.FileAnalysis)
	for _, a := range analyses {
		analysisMap[a.FilePath] = a
	}

	for _, feat := range data.Features {
		type featurePageData struct {
			Feature  Feature
			Analyses []indexer.FileAnalysis
		}

		var featureAnalyses []indexer.FileAnalysis
		for _, fp := range feat.Files {
			if a, ok := analysisMap[fp]; ok {
				featureAnalyses = append(featureAnalyses, a)
			}
		}

		pagePath := filepath.Join(featuresDir, feat.Slug+".md")
		pf, err := os.Create(pagePath)
		if err != nil {
			return err
		}

		err = featureTmpl.Execute(pf, featurePageData{
			Feature:  feat,
			Analyses: featureAnalyses,
		})
		pf.Close()
		if err != nil {
			return fmt.Errorf("executing feature template for %s: %w", feat.Name, err)
		}
	}

	return nil
}

// parseEnhancedIndexResponse extracts the project overview and features from the LLM response.
func parseEnhancedIndexResponse(content string) EnhancedIndex {
	var data EnhancedIndex

	// All section markers used in the enhanced index response.
	allMarkers := []string{
		"===PROJECT_OVERVIEW===",
		"===FEATURES===",
		"===ENTRY_POINTS===",
		"===EXIT_POINTS===",
		"===USAGES===",
		"===ARCHITECTURE_DIAGRAM===",
	}

	// findSectionEnd returns the index of the nearest following section marker.
	findSectionEnd := func(text, currentMarker string) int {
		end := len(text)
		for _, m := range allMarkers {
			if m == currentMarker {
				continue
			}
			if i := strings.Index(text, m); i >= 0 && i < end {
				end = i
			}
		}
		return end
	}

	// Extract PROJECT_OVERVIEW section.
	if idx := strings.Index(content, "===PROJECT_OVERVIEW==="); idx >= 0 {
		after := content[idx+len("===PROJECT_OVERVIEW==="):]
		end := findSectionEnd(after, "===PROJECT_OVERVIEW===")
		data.ProjectOverview = strings.TrimSpace(after[:end])
	}

	// Extract FEATURES section.
	if idx := strings.Index(content, "===FEATURES==="); idx >= 0 {
		after := content[idx+len("===FEATURES==="):]
		end := findSectionEnd(after, "===FEATURES===")
		featuresText := strings.TrimSpace(after[:end])

		// Split into feature blocks.
		lines := strings.Split(featuresText, "\n")
		var current *Feature
		for _, line := range lines {
			line = strings.TrimSpace(line)
			if line == "" {
				continue
			}

			if strings.HasPrefix(line, "FEATURE:") {
				if current != nil {
					current.Slug = slugify(current.Name)
					data.Features = append(data.Features, *current)
				}
				current = &Feature{
					Name: strings.TrimSpace(strings.TrimPrefix(line, "FEATURE:")),
				}
			} else if strings.HasPrefix(line, "DESCRIPTION:") && current != nil {
				current.Description = strings.TrimSpace(strings.TrimPrefix(line, "DESCRIPTION:"))
			} else if strings.HasPrefix(line, "FILES:") && current != nil {
				filesStr := strings.TrimSpace(strings.TrimPrefix(line, "FILES:"))
				for _, fp := range strings.Split(filesStr, ",") {
					fp = strings.TrimSpace(fp)
					if fp != "" {
						current.Files = append(current.Files, fp)
					}
				}
			}
		}
		// Don't forget the last feature.
		if current != nil {
			current.Slug = slugify(current.Name)
			data.Features = append(data.Features, *current)
		}
	}

	// Extract ENTRY_POINTS section.
	if idx := strings.Index(content, "===ENTRY_POINTS==="); idx >= 0 {
		after := content[idx+len("===ENTRY_POINTS==="):]
		end := findSectionEnd(after, "===ENTRY_POINTS===")
		lines := strings.Split(strings.TrimSpace(after[:end]), "\n")
		var current *EntryPoint
		for _, line := range lines {
			line = strings.TrimSpace(line)
			if line == "" {
				continue
			}
			if strings.HasPrefix(line, "ENTRY:") {
				if current != nil {
					data.EntryPoints = append(data.EntryPoints, *current)
				}
				current = &EntryPoint{
					Name: strings.TrimSpace(strings.TrimPrefix(line, "ENTRY:")),
				}
			} else if strings.HasPrefix(line, "TYPE:") && current != nil {
				current.Type = strings.TrimSpace(strings.TrimPrefix(line, "TYPE:"))
			} else if strings.HasPrefix(line, "DESCRIPTION:") && current != nil {
				current.Description = strings.TrimSpace(strings.TrimPrefix(line, "DESCRIPTION:"))
			}
		}
		if current != nil {
			data.EntryPoints = append(data.EntryPoints, *current)
		}
	}

	// Extract EXIT_POINTS section.
	if idx := strings.Index(content, "===EXIT_POINTS==="); idx >= 0 {
		after := content[idx+len("===EXIT_POINTS==="):]
		end := findSectionEnd(after, "===EXIT_POINTS===")
		lines := strings.Split(strings.TrimSpace(after[:end]), "\n")
		var current *ExitPoint
		for _, line := range lines {
			line = strings.TrimSpace(line)
			if line == "" {
				continue
			}
			if strings.HasPrefix(line, "EXIT:") {
				if current != nil {
					data.ExitPoints = append(data.ExitPoints, *current)
				}
				current = &ExitPoint{
					Name: strings.TrimSpace(strings.TrimPrefix(line, "EXIT:")),
				}
			} else if strings.HasPrefix(line, "TYPE:") && current != nil {
				current.Type = strings.TrimSpace(strings.TrimPrefix(line, "TYPE:"))
			} else if strings.HasPrefix(line, "DESCRIPTION:") && current != nil {
				current.Description = strings.TrimSpace(strings.TrimPrefix(line, "DESCRIPTION:"))
			}
		}
		if current != nil {
			data.ExitPoints = append(data.ExitPoints, *current)
		}
	}

	// Extract USAGES section.
	if idx := strings.Index(content, "===USAGES==="); idx >= 0 {
		after := content[idx+len("===USAGES==="):]
		end := findSectionEnd(after, "===USAGES===")
		lines := strings.Split(strings.TrimSpace(after[:end]), "\n")
		var current *UsageExample
		for _, line := range lines {
			line = strings.TrimSpace(line)
			if line == "" {
				continue
			}
			if strings.HasPrefix(line, "EXAMPLE:") {
				if current != nil {
					data.Usages = append(data.Usages, *current)
				}
				current = &UsageExample{
					Title: strings.TrimSpace(strings.TrimPrefix(line, "EXAMPLE:")),
				}
			} else if strings.HasPrefix(line, "COMMAND:") && current != nil {
				current.Command = strings.TrimSpace(strings.TrimPrefix(line, "COMMAND:"))
			} else if strings.HasPrefix(line, "DESCRIPTION:") && current != nil {
				current.Description = strings.TrimSpace(strings.TrimPrefix(line, "DESCRIPTION:"))
			}
		}
		if current != nil {
			data.Usages = append(data.Usages, *current)
		}
	}

	// Extract ARCHITECTURE_DIAGRAM section.
	if idx := strings.Index(content, "===ARCHITECTURE_DIAGRAM==="); idx >= 0 {
		after := content[idx+len("===ARCHITECTURE_DIAGRAM==="):]
		diagram := strings.TrimSpace(after)
		// Strip Mermaid fences if the LLM wrapped them.
		diagram = strings.TrimPrefix(diagram, "```mermaid")
		diagram = strings.TrimPrefix(diagram, "```")
		diagram = strings.TrimSuffix(diagram, "```")
		data.ArchDiagram = sanitizeMermaid(strings.TrimSpace(diagram))
	}

	// Fallback: if no markers were found, use the whole content as overview.
	if data.ProjectOverview == "" && len(data.Features) == 0 {
		data.ProjectOverview = strings.TrimSpace(content)
	}

	return data
}

// sanitizeMermaid quotes node labels that contain characters Mermaid treats as
// special syntax (parentheses, braces, etc.) to prevent parse errors.
var mermaidNodeLabel = regexp.MustCompile(`(\b\w+)\[([^\]"]+)\]`)

func sanitizeMermaid(diagram string) string {
	return mermaidNodeLabel.ReplaceAllStringFunc(diagram, func(match string) string {
		m := mermaidNodeLabel.FindStringSubmatch(match)
		if len(m) < 3 {
			return match
		}
		label := m[2]
		if strings.ContainsAny(label, "(){}|<>") {
			return m[1] + `["` + label + `"]`
		}
		return match
	})
}

// generateFeatureDetails makes concurrent LLM calls to produce a detailed
// multi-paragraph description for each feature. Failures are non-fatal; the
// short description is kept as a fallback.
func (g *DocGenerator) generateFeatureDetails(ctx context.Context, data *EnhancedIndex, analyses []indexer.FileAnalysis, provider llm.Provider, model string) {
	// Build lookup from file path to analysis.
	analysisMap := make(map[string]indexer.FileAnalysis, len(analyses))
	for _, a := range analyses {
		analysisMap[a.FilePath] = a
	}

	const maxConcurrency = 4
	sem := make(chan struct{}, maxConcurrency)
	var mu sync.Mutex
	var wg sync.WaitGroup

	for i := range data.Features {
		feat := &data.Features[i]

		// Collect file analyses for this feature.
		var fileSummaries strings.Builder
		for _, fp := range feat.Files {
			a, ok := analysisMap[fp]
			if !ok {
				continue
			}
			fmt.Fprintf(&fileSummaries, "\n### `%s`\n", a.FilePath)
			if a.Summary != "" {
				fmt.Fprintf(&fileSummaries, "Summary: %s\n", a.Summary)
			}
			if a.Purpose != "" {
				fmt.Fprintf(&fileSummaries, "Purpose: %s\n", a.Purpose)
			}
			if len(a.Functions) > 0 {
				fmt.Fprintf(&fileSummaries, "Key functions: ")
				names := make([]string, 0, len(a.Functions))
				for _, fn := range a.Functions {
					names = append(names, fn.Name)
				}
				fmt.Fprintf(&fileSummaries, "%s\n", strings.Join(names, ", "))
			}
			if len(a.Classes) > 0 {
				fmt.Fprintf(&fileSummaries, "Key types: ")
				names := make([]string, 0, len(a.Classes))
				for _, c := range a.Classes {
					names = append(names, c.Name)
				}
				fmt.Fprintf(&fileSummaries, "%s\n", strings.Join(names, ", "))
			}
			if len(a.Dependencies) > 0 {
				deps := make([]string, 0, len(a.Dependencies))
				for _, d := range a.Dependencies {
					deps = append(deps, d.Name)
				}
				fmt.Fprintf(&fileSummaries, "Dependencies: %s\n", strings.Join(deps, ", "))
			}
		}

		if fileSummaries.Len() == 0 {
			continue
		}

		wg.Add(1)
		go func(f *Feature, fileInfo string) {
			defer wg.Done()

			sem <- struct{}{}
			defer func() { <-sem }()

			prompt := fmt.Sprintf(`You are documenting the %q feature of this project.

This feature contains the following files:
%s

Write a comprehensive description (3-6 paragraphs) that explains:
1. What this feature does and why it exists
2. How it works internally — key components, data structures, algorithms
3. How the files work together — which file handles what, the flow between them
4. Important functions/types and what they do
5. How this feature integrates with the rest of the system

Be specific. Reference file paths in backticks. Name actual functions and types.
Do not use section headers or bullet lists — write flowing prose paragraphs.`, f.Name, fileInfo)

			resp, err := provider.Complete(ctx, llm.CompletionRequest{
				Model: model,
				Messages: []llm.Message{
					{Role: llm.RoleSystem, Content: "You are a technical writer producing detailed documentation for a software project. Be specific, reference actual code, and write clearly."},
					{Role: llm.RoleUser, Content: prompt},
				},
				MaxTokens:   2048,
				Temperature: 0.3,
			})
			if err != nil {
				return // graceful degradation: keep short description
			}

			detail := strings.TrimSpace(resp.Content)
			if detail != "" {
				mu.Lock()
				f.DetailedDescription = detail
				mu.Unlock()
			}
		}(feat, fileSummaries.String())
	}

	wg.Wait()
}

// slugify converts a string to a URL-safe slug.
func slugify(s string) string {
	s = strings.ToLower(s)
	s = strings.ReplaceAll(s, " ", "-")
	var out strings.Builder
	for _, c := range s {
		if (c >= 'a' && c <= 'z') || (c >= '0' && c <= '9') || c == '-' || c == '_' {
			out.WriteRune(c)
		}
	}
	return out.String()
}
