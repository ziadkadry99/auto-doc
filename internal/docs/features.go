package docs

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"text/template"

	"github.com/ziadkadry99/auto-doc/internal/diagrams"
	"github.com/ziadkadry99/auto-doc/internal/indexer"
	"github.com/ziadkadry99/auto-doc/internal/llm"
)

// Feature represents a logical grouping of related files in the project.
type Feature struct {
	Name                string
	Slug                string
	Description         string
	DetailedDescription string // Multi-paragraph deep description generated by a follow-up LLM call.
	Files               []string
}

// EntryPoint represents a way users or systems interact with the project.
type EntryPoint struct {
	Name, Type, Description string
}

// ExitPoint represents an output or side effect produced by the project.
type ExitPoint struct {
	Name, Type, Description string
}

// UsageExample represents a concrete usage example with a command and description.
type UsageExample struct {
	Title, Command, Description string
}

// EnhancedIndex holds data for the enhanced home page generation.
type EnhancedIndex struct {
	ProjectName     string
	ProjectOverview string
	Features        []Feature
	EntryPoints     []EntryPoint
	ExitPoints      []ExitPoint
	Usages          []UsageExample
	ArchDiagram     string
	DepDiagram      string
	Analyses        []indexer.FileAnalysis
}

// GenerateEnhancedIndex creates an enhanced index.md with project overview,
// feature-based TOC, and Mermaid diagrams. It also writes per-feature pages
// under features/{slug}.md.
func (g *DocGenerator) GenerateEnhancedIndex(ctx context.Context, analyses []indexer.FileAnalysis, provider llm.Provider, model string) error {
	// Build compact file summary for the LLM (truncate long summaries).
	var summary strings.Builder
	for _, a := range analyses {
		deps := ""
		if len(a.Dependencies) > 0 {
			var depNames []string
			for _, d := range a.Dependencies {
				depNames = append(depNames, d.Name)
			}
			deps = " [deps: " + strings.Join(depNames, ", ") + "]"
		}
		// Use a short version of the summary to keep the prompt compact.
		shortSummary := a.Summary
		if len(shortSummary) > 200 {
			shortSummary = shortSummary[:200] + "..."
		}
		fmt.Fprintf(&summary, "- %s: %s%s\n", a.FilePath, shortSummary, deps)
	}

	// If business context was provided, prepend it to the prompt.
	var contextSection string
	if g.BusinessContext != nil && !g.BusinessContext.IsEmpty() {
		contextSection = fmt.Sprintf("Business context provided by the project maintainer:\n%s\n", g.BusinessContext.ToPromptSection())
	}

	prompt := fmt.Sprintf(`%sGiven the following source files and their summaries, analyze this codebase.

Files:
%s

Respond with sections:

===PROJECT_OVERVIEW===
3-5 paragraph overview of what this project does, who it's for, main capabilities, technical approach.

===FEATURES===
Each feature as:
FEATURE: Name
DESCRIPTION: 2-4 sentences describing this feature.
FILES: comma-separated file paths

Every file must belong to exactly one feature. Aim for 4-12 features.

===ENTRY_POINTS===
List every way a user or external system can interact with this project (CLI commands, API endpoints, MCP tools, event handlers, etc.).
Each entry as:
ENTRY: Name of the entry point
TYPE: Category (e.g. CLI Command, API Endpoint, MCP Tool, Event Handler)
DESCRIPTION: What it does

===EXIT_POINTS===
List every output or side effect this project produces (files written, API calls made, databases updated, messages sent, etc.).
Each entry as:
EXIT: Name of the exit point
TYPE: Category (e.g. File Output, API Call, Database Write, Network Request)
DESCRIPTION: What it produces

===USAGES===
Provide concrete usage examples showing every major way to use this tool.
Each example as:
EXAMPLE: Short title
COMMAND: The exact command or code to run
DESCRIPTION: What happens when you run this and what to expect`, contextSection, summary.String())

	resp, err := provider.Complete(ctx, llm.CompletionRequest{
		Model: model,
		Messages: []llm.Message{
			{Role: llm.RoleSystem, Content: "You are a software architect analyzing a codebase. Be concise and factual. Group files by logical feature areas."},
			{Role: llm.RoleUser, Content: prompt},
		},
		MaxTokens:   12288,
		Temperature: 0.3,
	})
	if err != nil {
		return fmt.Errorf("enhanced index LLM call failed: %w", err)
	}

	data := parseEnhancedIndexResponse(resp.Content)
	data.ProjectName = projectNameFromWd(g.OutputDir)
	data.Analyses = analyses

	// Generate architecture diagram via a dedicated LLM call with focused prompt.
	data.ArchDiagram = generateArchitectureMermaid(ctx, data.Features, analyses, provider, model)
	if data.ArchDiagram == "" || !isMermaidDiagramValid(data.ArchDiagram) {
		fmt.Fprintf(os.Stderr, "Warning: invalid architecture mermaid from LLM; using fallback diagram\n")
		data.ArchDiagram = fallbackArchitectureDiagram(data.Features, analyses)
	}

	// Build dependency diagram from file analyses.
	depMap := make(map[string][]string)
	for _, a := range analyses {
		if len(a.Dependencies) > 0 {
			var deps []string
			for _, d := range a.Dependencies {
				deps = append(deps, d.Name)
			}
			depMap[a.FilePath] = deps
		}
	}
	if len(depMap) > 0 {
		data.DepDiagram = diagrams.DependencyDiagram(depMap)
	}

	// Generate detailed descriptions for each feature via concurrent LLM calls.
	g.generateFeatureDetails(ctx, &data, analyses, provider, model)

	// Generate interactive component map.
	if err := g.GenerateInteractiveMap(analyses, data.Features); err != nil {
		fmt.Fprintf(os.Stderr, "Warning: interactive map generation failed: %v\n", err)
	}

	// Write enhanced index.md.
	docsDir := filepath.Join(g.OutputDir, "docs")
	if err := os.MkdirAll(docsDir, 0o755); err != nil {
		return err
	}

	tmpl, err := template.New("enhancedIndex").Funcs(templateFuncs).Parse(enhancedIndexTemplate)
	if err != nil {
		return fmt.Errorf("parsing enhanced index template: %w", err)
	}

	indexPath := filepath.Join(docsDir, "index.md")
	f, err := os.Create(indexPath)
	if err != nil {
		return err
	}
	defer f.Close()

	if err := tmpl.Execute(f, data); err != nil {
		return fmt.Errorf("executing enhanced index template: %w", err)
	}

	// Write per-feature pages.
	featuresDir := filepath.Join(docsDir, "features")
	if err := os.MkdirAll(featuresDir, 0o755); err != nil {
		return err
	}

	featureTmpl, err := template.New("feature").Funcs(templateFuncs).Parse(featureTemplate)
	if err != nil {
		return fmt.Errorf("parsing feature template: %w", err)
	}

	// Build a lookup from file path to analysis for the feature pages.
	analysisMap := make(map[string]indexer.FileAnalysis)
	for _, a := range analyses {
		analysisMap[a.FilePath] = a
	}

	for _, feat := range data.Features {
		type featurePageData struct {
			Feature  Feature
			Analyses []indexer.FileAnalysis
		}

		var featureAnalyses []indexer.FileAnalysis
		for _, fp := range feat.Files {
			if a, ok := analysisMap[fp]; ok {
				featureAnalyses = append(featureAnalyses, a)
			}
		}

		pagePath := filepath.Join(featuresDir, feat.Slug+".md")
		pf, err := os.Create(pagePath)
		if err != nil {
			return err
		}

		err = featureTmpl.Execute(pf, featurePageData{
			Feature:  feat,
			Analyses: featureAnalyses,
		})
		pf.Close()
		if err != nil {
			return fmt.Errorf("executing feature template for %s: %w", feat.Name, err)
		}
	}

	return nil
}

// parseEnhancedIndexResponse extracts the project overview and features from the LLM response.
func parseEnhancedIndexResponse(content string) EnhancedIndex {
	var data EnhancedIndex

	// All section markers used in the enhanced index response.
	allMarkers := []string{
		"===PROJECT_OVERVIEW===",
		"===FEATURES===",
		"===ENTRY_POINTS===",
		"===EXIT_POINTS===",
		"===USAGES===",
	}

	// findSectionEnd returns the index of the nearest following section marker.
	findSectionEnd := func(text, currentMarker string) int {
		end := len(text)
		for _, m := range allMarkers {
			if m == currentMarker {
				continue
			}
			if i := strings.Index(text, m); i >= 0 && i < end {
				end = i
			}
		}
		return end
	}

	// Extract PROJECT_OVERVIEW section.
	if idx := strings.Index(content, "===PROJECT_OVERVIEW==="); idx >= 0 {
		after := content[idx+len("===PROJECT_OVERVIEW==="):]
		end := findSectionEnd(after, "===PROJECT_OVERVIEW===")
		data.ProjectOverview = strings.TrimSpace(after[:end])
	}

	// Extract FEATURES section.
	if idx := strings.Index(content, "===FEATURES==="); idx >= 0 {
		after := content[idx+len("===FEATURES==="):]
		end := findSectionEnd(after, "===FEATURES===")
		featuresText := strings.TrimSpace(after[:end])

		// Split into feature blocks.
		lines := strings.Split(featuresText, "\n")
		var current *Feature
		for _, line := range lines {
			line = strings.TrimSpace(line)
			if line == "" {
				continue
			}

			if strings.HasPrefix(line, "FEATURE:") {
				if current != nil {
					current.Slug = slugify(current.Name)
					data.Features = append(data.Features, *current)
				}
				current = &Feature{
					Name: strings.TrimSpace(strings.TrimPrefix(line, "FEATURE:")),
				}
			} else if strings.HasPrefix(line, "DESCRIPTION:") && current != nil {
				current.Description = strings.TrimSpace(strings.TrimPrefix(line, "DESCRIPTION:"))
			} else if strings.HasPrefix(line, "FILES:") && current != nil {
				filesStr := strings.TrimSpace(strings.TrimPrefix(line, "FILES:"))
				for _, fp := range strings.Split(filesStr, ",") {
					fp = strings.TrimSpace(fp)
					if fp != "" {
						current.Files = append(current.Files, fp)
					}
				}
			}
		}
		// Don't forget the last feature.
		if current != nil {
			current.Slug = slugify(current.Name)
			data.Features = append(data.Features, *current)
		}
	}

	// Extract ENTRY_POINTS section.
	if idx := strings.Index(content, "===ENTRY_POINTS==="); idx >= 0 {
		after := content[idx+len("===ENTRY_POINTS==="):]
		end := findSectionEnd(after, "===ENTRY_POINTS===")
		lines := strings.Split(strings.TrimSpace(after[:end]), "\n")
		var current *EntryPoint
		for _, line := range lines {
			line = strings.TrimSpace(line)
			if line == "" {
				continue
			}
			if strings.HasPrefix(line, "ENTRY:") {
				if current != nil {
					data.EntryPoints = append(data.EntryPoints, *current)
				}
				current = &EntryPoint{
					Name: strings.TrimSpace(strings.TrimPrefix(line, "ENTRY:")),
				}
			} else if strings.HasPrefix(line, "TYPE:") && current != nil {
				current.Type = strings.TrimSpace(strings.TrimPrefix(line, "TYPE:"))
			} else if strings.HasPrefix(line, "DESCRIPTION:") && current != nil {
				current.Description = strings.TrimSpace(strings.TrimPrefix(line, "DESCRIPTION:"))
			}
		}
		if current != nil {
			data.EntryPoints = append(data.EntryPoints, *current)
		}
	}

	// Extract EXIT_POINTS section.
	if idx := strings.Index(content, "===EXIT_POINTS==="); idx >= 0 {
		after := content[idx+len("===EXIT_POINTS==="):]
		end := findSectionEnd(after, "===EXIT_POINTS===")
		lines := strings.Split(strings.TrimSpace(after[:end]), "\n")
		var current *ExitPoint
		for _, line := range lines {
			line = strings.TrimSpace(line)
			if line == "" {
				continue
			}
			if strings.HasPrefix(line, "EXIT:") {
				if current != nil {
					data.ExitPoints = append(data.ExitPoints, *current)
				}
				current = &ExitPoint{
					Name: strings.TrimSpace(strings.TrimPrefix(line, "EXIT:")),
				}
			} else if strings.HasPrefix(line, "TYPE:") && current != nil {
				current.Type = strings.TrimSpace(strings.TrimPrefix(line, "TYPE:"))
			} else if strings.HasPrefix(line, "DESCRIPTION:") && current != nil {
				current.Description = strings.TrimSpace(strings.TrimPrefix(line, "DESCRIPTION:"))
			}
		}
		if current != nil {
			data.ExitPoints = append(data.ExitPoints, *current)
		}
	}

	// Extract USAGES section.
	if idx := strings.Index(content, "===USAGES==="); idx >= 0 {
		after := content[idx+len("===USAGES==="):]
		end := findSectionEnd(after, "===USAGES===")
		lines := strings.Split(strings.TrimSpace(after[:end]), "\n")
		var current *UsageExample
		var lastField string // tracks "command" or "description" for continuation lines
		for _, line := range lines {
			line = strings.TrimSpace(line)
			if line == "" {
				continue
			}
			if strings.HasPrefix(line, "EXAMPLE:") {
				if current != nil {
					data.Usages = append(data.Usages, *current)
				}
				current = &UsageExample{
					Title: strings.TrimSpace(strings.TrimPrefix(line, "EXAMPLE:")),
				}
				lastField = ""
			} else if strings.HasPrefix(line, "COMMAND:") && current != nil {
				current.Command = strings.TrimSpace(strings.TrimPrefix(line, "COMMAND:"))
				lastField = "command"
			} else if strings.HasPrefix(line, "DESCRIPTION:") && current != nil {
				current.Description = strings.TrimSpace(strings.TrimPrefix(line, "DESCRIPTION:"))
				lastField = "description"
			} else if current != nil {
				// Continuation line: append to the most recently set field.
				switch lastField {
				case "command":
					if current.Command != "" {
						current.Command += "\n" + line
					} else {
						current.Command = line
					}
				case "description":
					if current.Description != "" {
						current.Description += " " + line
					} else {
						current.Description = line
					}
				}
			}
		}
		if current != nil {
			data.Usages = append(data.Usages, *current)
		}
	}

	// Fallback: if no markers were found, use the whole content as overview.
	if data.ProjectOverview == "" && len(data.Features) == 0 {
		data.ProjectOverview = strings.TrimSpace(content)
	}

	return data
}

// sanitizeMermaid fixes common syntax issues in LLM-generated Mermaid diagrams.
// It sanitizes node IDs (removing &, #, etc.) and quotes labels containing
// special characters.
func sanitizeMermaid(diagram string) string {
	var out []string
	hasHeader := false
	subgraphDepth := 0
	for _, rawLine := range strings.Split(diagram, "\n") {
		line := strings.TrimSpace(rawLine)
		if line == "" || strings.HasPrefix(line, "```") {
			continue
		}
		switch {
		case strings.HasPrefix(line, "graph ") || strings.HasPrefix(line, "flowchart "):
			if !hasHeader {
				out = append(out, line)
				hasHeader = true
			}
		case strings.HasPrefix(line, "%%"):
			out = append(out, line)
		case strings.HasPrefix(line, "subgraph "):
			out = append(out, line)
			subgraphDepth++
		case line == "end" || line == "en":
			if subgraphDepth > 0 {
				out = append(out, "end")
				subgraphDepth--
			}
		case strings.HasPrefix(line, "classDef ") || strings.HasPrefix(line, "class ") || strings.HasPrefix(line, "style "):
			out = append(out, line)
		default:
			if fixed := sanitizeMermaidLine(rawLine); fixed != "" {
				out = append(out, fixed)
			}
		}
	}
	for subgraphDepth > 0 {
		out = append(out, "end")
		subgraphDepth--
	}
	if !hasHeader {
		out = append([]string{"graph TD"}, out...)
	}
	return strings.Join(out, "\n")
}

// mermaidNodeDef matches a node definition: ID["label"] or ID[label]
var mermaidNodeDef = regexp.MustCompile(`^(\s*)(\S+?)(\[.*)$`)

// mermaidArrow matches an arrow line: ID --> ID or ID -->|label| ID
var mermaidArrow = regexp.MustCompile(`^(\s*)(\S+?)(\s*-->.*)$`)

// mermaidArrowTarget matches the target node ID in an arrow (after --> or -->|...|)
var mermaidArrowTarget = regexp.MustCompile(`(-->(?:\|[^|]*\|)?\s*)(\S+)(.*)$`)

// sanitizeMermaidID replaces characters that are invalid in Mermaid node IDs.
func sanitizeMermaidID(id string) string {
	replacer := strings.NewReplacer(
		"&", "_",
		"#", "_",
		"@", "_",
		"!", "_",
		"?", "_",
		"(", "_",
		")", "_",
		"[", "_",
		"]", "_",
		"{", "_",
		"}", "_",
		"<", "_",
		">", "_",
		";", "_",
		",", "_",
		"'", "_",
		"\"", "_",
	)
	return replacer.Replace(id)
}

func sanitizeMermaidLine(line string) string {
	trimmed := strings.TrimSpace(line)

	// Skip directives, subgraph, end, empty lines, comments.
	if trimmed == "" || strings.HasPrefix(trimmed, "graph ") ||
		strings.HasPrefix(trimmed, "%%") || trimmed == "end" ||
		strings.HasPrefix(trimmed, "subgraph ") ||
		strings.HasPrefix(trimmed, "flowchart ") ||
		strings.HasPrefix(trimmed, "classDef ") ||
		strings.HasPrefix(trimmed, "class ") ||
		strings.HasPrefix(trimmed, "style ") {
		return line
	}

	// Arrow line FIRST: ID --> ID, ID -->|label| ID, or ID[label] --> ID[label]
	// Must check before node definitions so "A[x] --> B[y]" isn't swallowed
	// by the greedy bracket matcher in normalizeNodeRest.
	if m := mermaidArrow.FindStringSubmatch(line); m != nil {
		indent, rawSource, rest := m[1], m[2], m[3]

		sourceID, sourceLabel, sourceClass := parseNodeRef(rawSource)

		tm := mermaidArrowTarget.FindStringSubmatch(rest)
		if tm == nil {
			return ""
		}
		arrow := strings.TrimSpace(tm[1])
		rawTarget := strings.TrimSpace(tm[2] + tm[3])

		targetID, targetLabel, targetClass := parseNodeRef(rawTarget)

		var buf strings.Builder
		buf.WriteString(indent)
		buf.WriteString(sanitizeMermaidID(sourceID))
		if sourceLabel != "" {
			fmt.Fprintf(&buf, `["%s"]`, escapeMermaidLabel(sourceLabel))
		}
		buf.WriteString(sourceClass)
		fmt.Fprintf(&buf, " %s ", arrow)
		buf.WriteString(sanitizeMermaidID(targetID))
		if targetLabel != "" {
			fmt.Fprintf(&buf, `["%s"]`, escapeMermaidLabel(targetLabel))
		}
		buf.WriteString(targetClass)
		return buf.String()
	}

	// Node definition: ID[label] or ID["label"]
	if m := mermaidNodeDef.FindStringSubmatch(line); m != nil {
		indent, id, rest := m[1], m[2], m[3]
		normalized, ok := normalizeNodeRest(rest)
		if !ok {
			return ""
		}
		return indent + sanitizeMermaidID(id) + normalized
	}

	return ""
}

// parseNodeRef parses a node reference like "ID", "ID[label]", or
// "ID[label]:::class" into its component parts.
func parseNodeRef(s string) (id, label, class string) {
	s = strings.TrimSpace(s)

	// Extract :::class suffix (must be after any bracket label).
	// Look for ::: that is NOT inside brackets.
	bracketDepth := 0
	classIdx := -1
	for i := 0; i < len(s); i++ {
		switch s[i] {
		case '[':
			bracketDepth++
		case ']':
			bracketDepth--
		}
		if bracketDepth == 0 && i+3 <= len(s) && s[i:i+3] == ":::" {
			classIdx = i
			break
		}
	}
	if classIdx >= 0 {
		class = s[classIdx:]
		// Only keep the first word of the class (e.g. ":::highlight" not ":::highlight extra")
		if spIdx := strings.IndexByte(class, ' '); spIdx >= 0 {
			class = class[:spIdx]
		}
		s = s[:classIdx]
	}

	// Split ID and [label]
	bracketIdx := strings.Index(s, "[")
	if bracketIdx < 0 {
		return s, "", class
	}

	id = s[:bracketIdx]
	rest := s[bracketIdx:]

	// Find matching closing bracket.
	depth := 0
	end := -1
	for i, r := range rest {
		switch r {
		case '[':
			depth++
		case ']':
			depth--
			if depth == 0 {
				end = i
			}
		}
		if end >= 0 {
			break
		}
	}
	if end < 0 {
		return id, "", class
	}

	label = rest[1:end]
	// Strip surrounding quotes.
	if len(label) >= 2 && strings.HasPrefix(label, "\"") && strings.HasSuffix(label, "\"") {
		label = label[1 : len(label)-1]
	}

	return id, label, class
}

func normalizeNodeRest(rest string) (string, bool) {
	start := strings.Index(rest, "[")
	if start < 0 {
		return "", false
	}
	depth := 0
	end := -1
	for i, r := range rest[start:] {
		switch r {
		case '[':
			depth++
		case ']':
			depth--
			if depth == 0 {
				end = start + i
				break
			}
		}
	}
	if end < 0 {
		return "", false
	}

	label := strings.TrimSpace(rest[start+1 : end])
	if len(label) >= 2 && strings.HasPrefix(label, "\"") && strings.HasSuffix(label, "\"") {
		label = strings.TrimPrefix(strings.TrimSuffix(label, "\""), "\"")
	}
	suffix := strings.TrimSpace(rest[end+1:])
	if strings.HasPrefix(suffix, ":::") {
		parts := strings.Fields(suffix)
		if len(parts) > 0 {
			suffix = parts[0]
		} else {
			suffix = ""
		}
	} else {
		suffix = ""
	}
	return fmt.Sprintf("[\"%s\"]%s", escapeMermaidLabel(label), suffix), true
}

func escapeMermaidLabel(s string) string {
	s = strings.ReplaceAll(s, "\"", "#quot;")
	s = strings.ReplaceAll(s, "(", "#lpar;")
	s = strings.ReplaceAll(s, ")", "#rpar;")
	s = strings.ReplaceAll(s, "[", "#lsqb;")
	s = strings.ReplaceAll(s, "]", "#rsqb;")
	s = strings.ReplaceAll(s, "{", "#lbrace;")
	s = strings.ReplaceAll(s, "}", "#rbrace;")
	s = strings.ReplaceAll(s, "<", "#lt;")
	s = strings.ReplaceAll(s, ">", "#gt;")
	return s
}

func isMermaidDiagramValid(diagram string) bool {
	hasHeader := false
	subgraphDepth := 0
	nodeCount := 0
	edgeCount := 0
	nodesSeen := make(map[string]bool)
	for _, line := range strings.Split(diagram, "\n") {
		trimmed := strings.TrimSpace(line)
		if trimmed == "" || strings.HasPrefix(trimmed, "%%") {
			continue
		}
		switch {
		case strings.HasPrefix(trimmed, "graph ") || strings.HasPrefix(trimmed, "flowchart "):
			hasHeader = true
		case strings.HasPrefix(trimmed, "subgraph "):
			subgraphDepth++
		case trimmed == "end":
			if subgraphDepth == 0 {
				return false
			}
			subgraphDepth--
		case strings.HasPrefix(trimmed, "classDef ") || strings.HasPrefix(trimmed, "class ") || strings.HasPrefix(trimmed, "style "):
			continue
		default:
			if sanitizeMermaidLine(trimmed) == "" {
				return false
			}
			if strings.Contains(trimmed, "-->") {
				edgeCount++
				// Count unique nodes from arrow lines.
				if m := mermaidArrow.FindStringSubmatch(trimmed); m != nil {
					srcID, _, _ := parseNodeRef(m[2])
					if !nodesSeen[srcID] {
						nodesSeen[srcID] = true
						nodeCount++
					}
					if tm := mermaidArrowTarget.FindStringSubmatch(m[3]); tm != nil {
						tgtID, _, _ := parseNodeRef(strings.TrimSpace(tm[2] + tm[3]))
						if !nodesSeen[tgtID] {
							nodesSeen[tgtID] = true
							nodeCount++
						}
					}
				}
			} else if m := mermaidNodeDef.FindStringSubmatch(trimmed); m != nil {
				nid := m[2]
				if !nodesSeen[nid] {
					nodesSeen[nid] = true
					nodeCount++
				}
			}
		}
	}
	if nodeCount > 15 || edgeCount > 30 {
		return false
	}
	statementCount := nodeCount + edgeCount
	return hasHeader && subgraphDepth == 0 && statementCount > 0
}

// generateArchitectureMermaid makes a dedicated LLM call to produce a concise,
// high-level architecture diagram. It uses the already-parsed features (not raw
// file lists) so the LLM focuses on logical components rather than file paths.
func generateArchitectureMermaid(ctx context.Context, features []Feature, analyses []indexer.FileAnalysis, provider llm.Provider, model string) string {
	if len(features) == 0 {
		return ""
	}

	// Build component list from features.
	var components strings.Builder
	for _, f := range features {
		desc := f.Description
		if len(desc) > 120 {
			desc = desc[:120] + "..."
		}
		fmt.Fprintf(&components, "- %s: %s\n", f.Name, desc)
	}

	// Build condensed package-level dependency summary.
	fileToFeature := make(map[string]string, len(analyses))
	for _, f := range features {
		for _, fp := range f.Files {
			fileToFeature[fp] = f.Name
		}
	}
	depSeen := make(map[string]bool)
	var flows strings.Builder
	for _, a := range analyses {
		fromFeat, ok := fileToFeature[a.FilePath]
		if !ok {
			continue
		}
		for _, d := range a.Dependencies {
			toFeat, ok := fileToFeature[d.Name]
			if !ok || toFeat == fromFeat {
				continue
			}
			key := fromFeat + "->" + toFeat
			if depSeen[key] {
				continue
			}
			depSeen[key] = true
			fmt.Fprintf(&flows, "- %s depends on %s\n", fromFeat, toFeat)
		}
	}
	if flows.Len() == 0 {
		flows.WriteString("(no direct inter-component dependencies detected)\n")
	}

	prompt := fmt.Sprintf(`You are generating a high-level architecture diagram for a software project.

The project has these major components:
%s
Key data flows between components:
%s
Generate a Mermaid "graph TD" diagram following these STRICT rules:
1. Use 5-10 nodes maximum. Each node is a logical component, NOT a file or directory.
2. Node labels should be short (2-4 words). Use human-readable names, not file paths.
3. Group nodes into 2-4 subgraph layers (e.g. "Interface", "Core", "Storage", "External").
4. Arrows represent data flow and control flow, NOT import relationships.
5. Each node should have at most 4-5 connections.
6. Do NOT use file paths, directory names, or package names as node IDs or labels.

Output ONLY the Mermaid code. No fences, no explanation.`, components.String(), flows.String())

	resp, err := provider.Complete(ctx, llm.CompletionRequest{
		Model: model,
		Messages: []llm.Message{
			{Role: llm.RoleSystem, Content: "You are a software architect producing a concise Mermaid architecture diagram. Output only valid Mermaid syntax."},
			{Role: llm.RoleUser, Content: prompt},
		},
		MaxTokens:   2048,
		Temperature: 0.2,
	})
	if err != nil {
		fmt.Fprintf(os.Stderr, "Warning: architecture diagram LLM call failed: %v\n", err)
		return ""
	}

	diagram := strings.TrimSpace(resp.Content)
	// Strip Mermaid fences if the LLM wrapped them.
	diagram = strings.TrimPrefix(diagram, "```mermaid")
	diagram = strings.TrimPrefix(diagram, "```")
	diagram = strings.TrimSuffix(diagram, "```")
	return sanitizeMermaid(strings.TrimSpace(diagram))
}

func fallbackArchitectureDiagram(features []Feature, analyses []indexer.FileAnalysis) string {
	if len(features) == 0 {
		return "graph TD\n    App[\"Application\"]"
	}

	// Cap at 10 features — merge the smallest ones if needed.
	feats := features
	if len(feats) > 10 {
		feats = feats[:10]
	}

	// Infer layers from feature names/descriptions for subgraph grouping.
	type layerInfo struct {
		name     string
		keywords []string
	}
	layers := []layerInfo{
		{"Interface", []string{"cli", "command", "api", "endpoint", "server", "handler", "http", "grpc", "mcp", "ui", "frontend"}},
		{"Core", []string{"engine", "core", "index", "pipeline", "process", "analyz", "logic", "walker", "traversal"}},
		{"Storage", []string{"store", "storage", "database", "db", "vector", "embed", "persist", "cache"}},
		{"Output", []string{"output", "doc", "generat", "render", "template", "diagram", "site", "report", "format"}},
	}

	layerFeatures := make(map[string][]Feature)
	assigned := make(map[string]bool)
	for _, feat := range feats {
		lower := strings.ToLower(feat.Name + " " + feat.Description)
		for _, l := range layers {
			for _, kw := range l.keywords {
				if strings.Contains(lower, kw) && !assigned[feat.Name] {
					layerFeatures[l.name] = append(layerFeatures[l.name], feat)
					assigned[feat.Name] = true
					break
				}
			}
			if assigned[feat.Name] {
				break
			}
		}
		if !assigned[feat.Name] {
			layerFeatures["Core"] = append(layerFeatures["Core"], feat)
		}
	}

	// Build cross-feature dependency relationships.
	fileToFeature := make(map[string]string, len(analyses))
	for _, feat := range feats {
		for _, fp := range feat.Files {
			fileToFeature[fp] = feat.Name
		}
	}
	seen := make(map[string]bool)
	var relationships []diagrams.Relationship
	for _, a := range analyses {
		fromFeat, ok := fileToFeature[a.FilePath]
		if !ok {
			continue
		}
		for _, d := range a.Dependencies {
			toFeat, ok := fileToFeature[d.Name]
			if !ok || toFeat == fromFeat {
				continue
			}
			key := fromFeat + "->" + toFeat
			if seen[key] {
				continue
			}
			seen[key] = true
			relationships = append(relationships, diagrams.Relationship{From: fromFeat, To: toFeat})
		}
	}

	// Build diagram with subgraphs.
	var b strings.Builder
	b.WriteString("graph TD\n")

	sanitizeID := func(s string) string {
		r := strings.NewReplacer("/", "_", "\\", "_", ".", "_", "-", "_", " ", "_",
			"(", "_", ")", "_", "[", "_", "]", "_", "{", "_", "}", "_", ":", "_")
		return r.Replace(s)
	}
	escape := func(s string) string {
		s = strings.ReplaceAll(s, "\"", "#quot;")
		s = strings.ReplaceAll(s, "(", "#lpar;")
		s = strings.ReplaceAll(s, ")", "#rpar;")
		s = strings.ReplaceAll(s, "[", "#lsqb;")
		s = strings.ReplaceAll(s, "]", "#rsqb;")
		s = strings.ReplaceAll(s, "{", "#lbrace;")
		s = strings.ReplaceAll(s, "}", "#rbrace;")
		s = strings.ReplaceAll(s, "<", "#lt;")
		s = strings.ReplaceAll(s, ">", "#gt;")
		return s
	}

	// Write subgraphs for layers that have features.
	for _, l := range layers {
		lf, ok := layerFeatures[l.name]
		if !ok || len(lf) == 0 {
			continue
		}
		fmt.Fprintf(&b, "    subgraph %s\n", l.name)
		for _, feat := range lf {
			fmt.Fprintf(&b, "        %s[\"%s\"]\n", sanitizeID(feat.Name), escape(feat.Name))
		}
		b.WriteString("    end\n")
	}

	// Write relationships.
	if len(relationships) > 0 {
		for _, r := range relationships {
			fmt.Fprintf(&b, "    %s --> %s\n", sanitizeID(r.From), sanitizeID(r.To))
		}
	} else {
		// No relationships found — connect adjacent layers for minimal structure.
		var layerReps []string
		for _, l := range layers {
			if lf, ok := layerFeatures[l.name]; ok && len(lf) > 0 {
				layerReps = append(layerReps, lf[0].Name)
			}
		}
		for i := 0; i < len(layerReps)-1; i++ {
			fmt.Fprintf(&b, "    %s --> %s\n", sanitizeID(layerReps[i]), sanitizeID(layerReps[i+1]))
		}
	}

	return strings.TrimRight(b.String(), "\n")
}

// generateFeatureDetails makes concurrent LLM calls to produce a detailed
// multi-paragraph description for each feature. Failures are non-fatal; the
// short description is kept as a fallback.
func (g *DocGenerator) generateFeatureDetails(ctx context.Context, data *EnhancedIndex, analyses []indexer.FileAnalysis, provider llm.Provider, model string) {
	// Build lookup from file path to analysis.
	analysisMap := make(map[string]indexer.FileAnalysis, len(analyses))
	for _, a := range analyses {
		analysisMap[a.FilePath] = a
	}

	const maxConcurrency = 4
	sem := make(chan struct{}, maxConcurrency)
	var mu sync.Mutex
	var wg sync.WaitGroup

	for i := range data.Features {
		feat := &data.Features[i]

		// Collect file analyses for this feature.
		var fileSummaries strings.Builder
		for _, fp := range feat.Files {
			a, ok := analysisMap[fp]
			if !ok {
				continue
			}
			fmt.Fprintf(&fileSummaries, "\n### `%s`\n", a.FilePath)
			if a.Summary != "" {
				fmt.Fprintf(&fileSummaries, "Summary: %s\n", a.Summary)
			}
			if a.Purpose != "" {
				fmt.Fprintf(&fileSummaries, "Purpose: %s\n", a.Purpose)
			}
			if len(a.Functions) > 0 {
				fmt.Fprintf(&fileSummaries, "Key functions: ")
				names := make([]string, 0, len(a.Functions))
				for _, fn := range a.Functions {
					names = append(names, fn.Name)
				}
				fmt.Fprintf(&fileSummaries, "%s\n", strings.Join(names, ", "))
			}
			if len(a.Classes) > 0 {
				fmt.Fprintf(&fileSummaries, "Key types: ")
				names := make([]string, 0, len(a.Classes))
				for _, c := range a.Classes {
					names = append(names, c.Name)
				}
				fmt.Fprintf(&fileSummaries, "%s\n", strings.Join(names, ", "))
			}
			if len(a.Dependencies) > 0 {
				deps := make([]string, 0, len(a.Dependencies))
				for _, d := range a.Dependencies {
					deps = append(deps, d.Name)
				}
				fmt.Fprintf(&fileSummaries, "Dependencies: %s\n", strings.Join(deps, ", "))
			}
		}

		if fileSummaries.Len() == 0 {
			continue
		}

		wg.Add(1)
		go func(f *Feature, fileInfo string) {
			defer wg.Done()

			sem <- struct{}{}
			defer func() { <-sem }()

			prompt := fmt.Sprintf(`You are documenting the %q feature of this project.

This feature contains the following files:
%s

Write a comprehensive description (3-6 paragraphs) that explains:
1. What this feature does and why it exists
2. How it works internally — key components, data structures, algorithms
3. How the files work together — which file handles what, the flow between them
4. Important functions/types and what they do
5. How this feature integrates with the rest of the system

Be specific. Reference file paths in backticks. Name actual functions and types.
Do not use section headers or bullet lists — write flowing prose paragraphs.`, f.Name, fileInfo)

			resp, err := provider.Complete(ctx, llm.CompletionRequest{
				Model: model,
				Messages: []llm.Message{
					{Role: llm.RoleSystem, Content: "You are a technical writer producing detailed documentation for a software project. Be specific, reference actual code, and write clearly."},
					{Role: llm.RoleUser, Content: prompt},
				},
				MaxTokens:   2048,
				Temperature: 0.3,
			})
			if err != nil {
				return // graceful degradation: keep short description
			}

			detail := strings.TrimSpace(resp.Content)
			if detail != "" {
				mu.Lock()
				f.DetailedDescription = detail
				mu.Unlock()
			}
		}(feat, fileSummaries.String())
	}

	wg.Wait()
}

// slugify converts a string to a URL-safe slug.
func slugify(s string) string {
	s = strings.ToLower(s)
	s = strings.ReplaceAll(s, " ", "-")
	var out strings.Builder
	for _, c := range s {
		if (c >= 'a' && c <= 'z') || (c >= '0' && c <= '9') || c == '-' || c == '_' {
			out.WriteRune(c)
		}
	}
	return out.String()
}
